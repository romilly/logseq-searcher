{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logseq Full-Text Search with Embeddings\n",
    "\n",
    "This notebook loads markdown documents from a Logseq vault into PostgreSQL with:\n",
    "- Full-text search (FTS) for keyword matching\n",
    "- Vector embeddings for semantic search\n",
    "- Hybrid search combining both approaches\n",
    "\n",
    "## Setup\n",
    "\n",
    "Create a `.env` file in the project root with:\n",
    "```\n",
    "DB_HOST=your_host\n",
    "DB_PORT=5432\n",
    "DB_NAME=your_database\n",
    "DB_USER=your_user\n",
    "DB_PASSWORD=your_password\n",
    "\n",
    "OLLAMA_HOST=http://your_ollama_host:11434\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:08:59.405835577Z",
     "start_time": "2025-12-23T11:08:59.388203935Z"
    }
   },
   "source": [
    "# Workaround for PyCharm not adding src to PYTHONPATH\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = str(Path.cwd().parent / 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:09:01.022382057Z",
     "start_time": "2025-12-23T11:08:59.408909201Z"
    }
   },
   "source": [
    "from logseq_searcher import (\n",
    "    # Database\n",
    "    init_db,\n",
    "    create_schema,\n",
    "    # Embeddings\n",
    "    init_ollama,\n",
    "    # Loading\n",
    "    load_logseq_vault,\n",
    "    add_embeddings_to_existing,\n",
    "    # Search\n",
    "    search,\n",
    "    advanced_search,\n",
    "    get_document,\n",
    "    get_document_count,\n",
    "    semantic_search,\n",
    "    hybrid_search,\n",
    ")\n",
    "\n",
    "# Initialize database and Ollama connections from .env file\n",
    "init_db(Path('../.env'))\n",
    "init_ollama()  # Uses OLLAMA_HOST from .env\n",
    "print(\"Database and Ollama initialized\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database and Ollama initialized\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:09:01.560146982Z",
     "start_time": "2025-12-23T11:09:01.070063933Z"
    }
   },
   "source": [
    "# Path to logseq vault\n",
    "LOGSEQ_PATH = Path.home() / 'git' / 'active' / 'logseq-personal'\n",
    "\n",
    "print(f\"Logseq vault: {LOGSEQ_PATH}\")\n",
    "print(f\"Pages directory exists: {(LOGSEQ_PATH / 'pages').exists()}\")\n",
    "print(f\"Journals directory exists: {(LOGSEQ_PATH / 'journals').exists()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logseq vault: /home/romilly/git/active/logseq-personal\n",
      "Pages directory exists: True\n",
      "Journals directory exists: True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Schema\n",
    "\n",
    "Creates a `documents` table with:\n",
    "- `id`: Auto-incrementing primary key\n",
    "- `filename`: Original filename\n",
    "- `doc_type`: Either 'page' or 'journal'\n",
    "- `title`: Document title (derived from filename)\n",
    "- `content`: Full markdown content\n",
    "- `content_tsv`: Full-text search vector (auto-generated)\n",
    "- `embedding`: 768-dimensional vector for semantic search\n",
    "- `created_at`: Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:21:55.614006225Z",
     "start_time": "2025-12-23T11:21:55.484994363Z"
    }
   },
   "source": [
    "create_schema()\n",
    "print(\"Schema created successfully (with pgvector support)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created successfully (with pgvector support)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n",
    "\n",
    "You can load documents with or without embeddings:\n",
    "- Without embeddings: Fast, FTS-only search\n",
    "- With embeddings: Slower loading, enables semantic and hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:22:16.481800669Z",
     "start_time": "2025-12-23T11:22:00.387963636Z"
    }
   },
   "source": [
    "# Load WITHOUT embeddings (fast)\n",
    "result = load_logseq_vault(LOGSEQ_PATH)\n",
    "print(f\"Loaded {result['pages']} pages and {result['journals']} journals\")\n",
    "print(f\"Total: {result['total']} documents\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3307 pages and 1491 journals\n",
      "Total: 4798 documents\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:22:16.577364014Z",
     "start_time": "2025-12-23T11:22:16.499118950Z"
    }
   },
   "source": [
    "# Verify the data was loaded\n",
    "counts = get_document_count()\n",
    "for doc_type, count in counts.items():\n",
    "    print(f\"{doc_type}: {count} documents\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 3307 documents\n",
      "journal: 1491 documents\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Embeddings to Existing Documents\n",
    "\n",
    "This generates embeddings for documents that don't have them yet.\n",
    "Processing ~4800 documents takes some time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:09.195486607Z",
     "start_time": "2025-12-23T11:31:09.075530455Z"
    }
   },
   "source": [
    "def progress(processed, total):\n",
    "    print(f\"\\rProcessed {processed}/{total} documents ({100*processed//total}%)\", end=\"\")\n",
    "\n",
    "add_embeddings_to_existing(batch_size=50, progress_callback=progress)\n",
    "print(\"\\nEmbeddings complete!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings complete!\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Text Search (FTS)\n",
    "\n",
    "Traditional keyword-based search. Fast and precise for exact term matching."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:11.767105049Z",
     "start_time": "2025-12-23T11:31:11.752129877Z"
    }
   },
   "source": [
    "def display_fts_results(results: list):\n",
    "    \"\"\"Display FTS results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(results)} result(s):\\n\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['doc_type']}] {r['title']}\")\n",
    "        print(f\"   Rank: {r['rank']:.4f}\")\n",
    "        print(f\"   {r['headline']}\")\n",
    "        print()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:13.487851497Z",
     "start_time": "2025-12-23T11:31:13.378826757Z"
    }
   },
   "source": [
    "# Example: FTS for \"Feynman\"\n",
    "results = search(\"Feynman\", limit=5)\n",
    "display_fts_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 result(s):\n",
      "\n",
      "1. [page] book%2FRichard Feynman’s Mental Models\n",
      "   Rank: 0.7552\n",
      "   >>>Feynman<<<’s Mental Models\n",
      "author:: [[Peter Hollins]]\n",
      "full-title:: \"Richard >>>Feynman<<<’s Mental Models\"\n",
      "category:: #books\n",
      "![](https://m.media-amazon.com/images/I/61xB09TwRiL._SY160.jpg)\n",
      "\n",
      "- what\n",
      "\n",
      "2. [page] person%2FRichard Feynman\n",
      "   Rank: 0.6687\n",
      "   alias:: >>>Feynman<<<\n",
      "\n",
      "-\n",
      "\n",
      "3. [page] The Feynman Technique for Learning\n",
      "   Rank: 0.6079\n",
      "   - https://www.colorado.edu/artssciences-advising/resource-library/life-skills/the-feynman-technique-in-academic-coaching\n",
      "- https://fs.blog/feynman-technique/\n",
      "- Can I do this using #GPT as my audience? Is there a good prompt\n",
      "\n",
      "4. [page] 12 Favorite Problems\n",
      "   Rank: 0.3881\n",
      "   >>>Feynman<<<]]\n",
      "- Richard Phillips >>>Feynman<<< was one of the most important scientists of the 20th century.  Born on the outskirts of New York\n",
      "\n",
      "5. [page] How to Generate Your Own Favorite Problems\n",
      "   Rank: 0.3040\n",
      "   >>>Feynman<<<\n",
      "- In this step-by-step guide, I’ll share the exact process I use for myself and my students\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: FTS only in journals\n",
    "results = search(\"Roam\", limit=5, doc_type='journal')\n",
    "display_fts_results(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "\n",
    "Uses vector embeddings to find semantically similar documents.\n",
    "Can find relevant results even without exact keyword matches."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:17.554019833Z",
     "start_time": "2025-12-23T11:31:17.544564973Z"
    }
   },
   "source": [
    "def display_semantic_results(results: list):\n",
    "    \"\"\"Display semantic search results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(results)} result(s):\\n\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['doc_type']}] {r['title']}\")\n",
    "        print(f\"   Similarity: {r['similarity']:.4f}\")\n",
    "        print(f\"   {r['snippet'][:100]}...\")\n",
    "        print()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:21.741802153Z",
     "start_time": "2025-12-23T11:31:21.558083948Z"
    }
   },
   "source": [
    "# Example: Semantic search for concepts\n",
    "results = semantic_search(\"learning techniques for better memory\", limit=5)\n",
    "display_semantic_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 result(s):\n",
      "\n",
      "1. [page] Cognitive Load\n",
      "   Similarity: 0.7393\n",
      "   ---\n",
      "title: Cognitive Load\n",
      "---\n",
      "\n",
      "- [Cognitive Load Theory - Learning Skills From MindTools.com](https:...\n",
      "\n",
      "2. [page] papers-Computational principles of memory\n",
      "   Similarity: 0.7247\n",
      "   ---\n",
      "title: papers/Computational principles of memory\n",
      "---\n",
      "\n",
      "- https://www.nature.com/articles/nn.4237\n",
      "...\n",
      "\n",
      "3. [page] memory\n",
      "   Similarity: 0.7112\n",
      "   ---\n",
      "title: memory\n",
      "---\n",
      "\n",
      "- Retrieving a [[memory]] is like placing a piece in a jigsaw puzzle. The mor...\n",
      "\n",
      "4. [page] Spaced Repetition\n",
      "   Similarity: 0.6502\n",
      "   ---\n",
      "title: Spaced Repetition\n",
      "---\n",
      "\n",
      "- Based on research by [[person/Ebbinghaus]] and subsequently conf...\n",
      "\n",
      "5. [page] How to Teach Yourself Anything\n",
      "   Similarity: 0.6451\n",
      "   - Spectrum of learning styles\n",
      "\t- Structured <-> Opportunistic\n",
      "\t- Studying <-> Doing\n",
      "\t- Maximise valu...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:30.972434052Z",
     "start_time": "2025-12-23T11:31:30.794881110Z"
    }
   },
   "source": [
    "# Example: Semantic search for related ideas\n",
    "results = semantic_search(\"productivity and time management\", limit=5)\n",
    "display_semantic_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 result(s):\n",
      "\n",
      "1. [page] Time Management\n",
      "   Similarity: 0.6529\n",
      "   ---\n",
      "title: Time Management\n",
      "---\n",
      "\n",
      "- https://blog.nateliason.com/p/addicted-to-speed [[person/Nat Elias...\n",
      "\n",
      "2. [page] productivity\n",
      "   Similarity: 0.6337\n",
      "   ---\n",
      "title: productivity\n",
      "---\n",
      "\n",
      "- If I spend 30% of my time improving my skills, and as a result I beco...\n",
      "\n",
      "3. [page] project%2FPimoroni booklet%2FTask05\n",
      "   Similarity: 0.6186\n",
      "   ### Task 5: Estimating Completion Time for Remaining Tasks\n",
      "- **Objective**: Estimate how much time e...\n",
      "\n",
      "4. [page] Work\n",
      "   Similarity: 0.6000\n",
      "   ---\n",
      "title: Work\n",
      "---\n",
      "\n",
      "- Work on a book or video for two hours\n",
      "\t - Pomodoros\n",
      "\t\t - {{POMO  25}}\n",
      "\n",
      "- Afte...\n",
      "\n",
      "5. [page] Weekly priorities\n",
      "   Similarity: 0.5842\n",
      "   - Work **using** #Ultraworking\n",
      "\t- 1 hour/day on [[project/s2ag-corpus]]\n",
      "\t\t- 30 mins on README\n",
      "\t\t- fi...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "\n",
    "Combines full-text search and semantic similarity for best results.\n",
    "You can adjust the weights to favor keywords or meaning."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:40.258690048Z",
     "start_time": "2025-12-23T11:31:40.242804494Z"
    }
   },
   "source": [
    "def display_hybrid_results(results: list):\n",
    "    \"\"\"Display hybrid search results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(results)} result(s):\\n\")\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['doc_type']}] {r['title']}\")\n",
    "        print(f\"   Combined: {r['combined_score']:.4f} (FTS: {r['fts_rank']:.4f}, Semantic: {r['similarity']:.4f})\")\n",
    "        print(f\"   {r['headline']}\")\n",
    "        print()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:31:44.769658171Z",
     "start_time": "2025-12-23T11:31:44.459576120Z"
    }
   },
   "source": [
    "# Example: Hybrid search (equal weights)\n",
    "results = hybrid_search(\"Python programming\", limit=5)\n",
    "display_hybrid_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 result(s):\n",
      "\n",
      "1. [page] Python Developers%3A don't confuse OO Programming with OO design!\n",
      "   Combined: 0.8077 (FTS: 0.9350, Semantic: 0.6804)\n",
      "   ---\n",
      "title: >>>Python<<< Developers: don't confuse OO >>>Programming<<< with OO design!\n",
      "---\n",
      "\n",
      "- #planned #aa\n",
      "\n",
      "2. [page] book%2FPractical Python Artificial Intelligence Programming\n",
      "   Combined: 0.7834 (FTS: 0.9736, Semantic: 0.5931)\n",
      "   - book\n",
      "\t- version 1.1.2\n",
      "\t- Title:\n",
      "\t- Authors:\n",
      "\t- ISBN:\n",
      "\t- scores: 1 is bad, 5 is excellent\n",
      "\t\t- overall:\n",
      "\t\t- readable:\n",
      "\t\t- breadth:\n",
      "\t\t- depth:\n",
      "\t\t- credible:\n",
      "\t\t- current:\n",
      "\t- tags\n",
      "\n",
      "3. [page] hls__Online-Python-Tutor-web-based-program-visualization_SIGCSE-2013_1740912753104_0\n",
      "   Combined: 0.7711 (FTS: 0.9524, Semantic: 0.5898)\n",
      "   file:: [Online-Python-Tutor-web-based-program-visualization_SIGCSE-2013_1740912753104_0.pdf](../assets/Online-Python-Tutor-web-based-program-visualization_SIGCSE-2013_1740912753104_0.pdf)\n",
      "file-path:: ../assets/Online-Python-Tutor-web-based-program-visualization_SIGCSE-2013_1740912753104_0.pdf\n",
      "\n",
      "\n",
      "4. [journal] 2023_05_03\n",
      "   Combined: 0.7543 (FTS: 0.9119, Semantic: 0.5967)\n",
      "   >>>Python<<< Artificial Intelligence >>>Programming<<<]]\n",
      "\t\t\t\t- \"Practical >>>Python<<< Artificial Intelligence >>>Programming<<<\" by Mark Watson is a book that focuses on using >>>Python<<<\n",
      "\n",
      "5. [page] Rust\n",
      "   Combined: 0.7206 (FTS: 0.8617, Semantic: 0.5796)\n",
      "   >>>Python<<<\n",
      "  collapsed:: true\n",
      "\t- Yes, you can call Rust code from >>>Python<<<. This interoperability is particularly useful for leveraging Rust's performance benefits in a >>>Python<<< >>>program<<<\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:32:08.355805766Z",
     "start_time": "2025-12-23T11:32:08.035113567Z"
    }
   },
   "source": [
    "# Example: Hybrid search favoring semantic similarity\n",
    "results = hybrid_search(\"learning from mistakes\", limit=5, fts_weight=0.3, semantic_weight=0.7)\n",
    "display_hybrid_results(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 result(s):\n",
      "\n",
      "1. [page] Learning from Mistakes\n",
      "   Combined: 0.7161 (FTS: 0.9998, Semantic: 0.5946)\n",
      "   >>>learning<<< #brain #[[Reinforcement >>>Learning<<<]]\n",
      "- Via [[ChatGPT]]\n",
      "\t- What evidence is there that the brain >>>learns<<< best by making >>>mistakes<<<?\n",
      "\t\t- There is evidence\n",
      "\n",
      "2. [page] four stages of competence\n",
      "   Combined: 0.5128 (FTS: 0.3412, Semantic: 0.5864)\n",
      "   >>>learn<<<.[[1]](https://en.wikipedia.org/wiki/Four_stages_of_competence#cite_note-In_the_Mush-1)\n",
      "\t\t- **Conscious incompetence**\n",
      "\t\t\t- Though the individual does not understand or know how to do something, they recognize the deficit, as well as the value of a new skill in addressing the deficit. The making of >>>mistakes<<<\n",
      "\n",
      "3. [page] book%2FThe Not to Do List\n",
      "   Combined: 0.4782 (FTS: 0.7335, Semantic: 0.3689)\n",
      "   >>>Learning<<< from your own >>>mistakes<<< is all well and good, but >>>learning<<< from other people’s >>>mistakes<<< is golden. ([Location\n",
      "\n",
      "4. [page] downloads%2FStartup Company Culture\n",
      "   Combined: 0.4769 (FTS: 0.5598, Semantic: 0.4413)\n",
      "   >>>mistakes<<< along the way. It's OK to make >>>mistakes<<<: if you never make any >>>mistakes<<<, then you probably aren't being aggressive enough.\n",
      "\n",
      "However, when you make >>>mistakes<<< it's important to recognize them quickly, >>>learn<<<\n",
      "\n",
      "5. [page] ACT-R\n",
      "   Combined: 0.4598 (FTS: 0.5307, Semantic: 0.4294)\n",
      "   >>>Mistakes<<< in the process waste time and do not contribute to >>>learning<<<. Thus Anderson advocates for intelligent tutors who immediately\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: Hybrid search favoring keyword matching\n",
    "results = hybrid_search(\"Raspberry Pi\", limit=5, fts_weight=0.7, semantic_weight=0.3)\n",
    "display_hybrid_results(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced FTS Search\n",
    "\n",
    "For more control, use `advanced_search` which supports:\n",
    "- `\"quoted phrases\"`\n",
    "- `OR` for alternatives\n",
    "- `-` for exclusion"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: Search for exact phrase\n",
    "results = advanced_search('\"favorite problems\"', limit=5)\n",
    "display_fts_results(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get a specific document by ID\n",
    "# doc = get_document(1)\n",
    "# print(doc['content'][:500])"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
